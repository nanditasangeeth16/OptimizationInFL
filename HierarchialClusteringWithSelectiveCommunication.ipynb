{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.cluster.hierarchy import linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNMnist, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        #self.idxs = list(idxs)\n",
    "        self.idxs = np.array(idxs).astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #image, label = self.dataset[self.idxs[item]]\n",
    "        item = int(item)\n",
    "        idx = int(self.idxs[item])\n",
    "        image,label = self.dataset[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Loading\n",
    "data_dir = 'D:/mnist_data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalUpdate(object):\n",
    "    def __init__(self, dataset, idxs, local_bs=32, local_ep=3, lr=0.01, momentum=0.5):\n",
    "        self.trainloader = DataLoader(\n",
    "            DatasetSplit(dataset, idxs),\n",
    "            batch_size=local_bs,\n",
    "            shuffle=True\n",
    "        )\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.local_ep = local_ep\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def update_weights(self, model):\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=self.lr,\n",
    "            momentum=self.momentum\n",
    "        )\n",
    "\n",
    "        epoch_loss = []\n",
    "        for _ in range(self.local_ep):\n",
    "            batch_loss = []\n",
    "            for batch_idx, (images, labels) in enumerate(self.trainloader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                log_probs = model(images)\n",
    "                loss = self.criterion(log_probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "        return model.state_dict(), sum(epoch_loss)/len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_iid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    Sample IID client data from MNIST dataset\n",
    "    :param dataset: MNIST dataset\n",
    "    :param num_users: Number of users\n",
    "    :return: Dictionary of user groups\n",
    "    \"\"\"\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "\n",
    "\n",
    "def mnist_noniid(dataset, num_users=10):\n",
    "    \"\"\"\n",
    "    Sample non-I.I.D client data by assigning specific digits to each client\n",
    "    \"\"\"\n",
    "    labels = dataset.targets.numpy()\n",
    "    dict_users = {i: np.array([], dtype='int64') for i in range(num_users)}\n",
    "    \n",
    "    # Digit distribution for 5 clients (can be adjusted)\n",
    "    client_digits = {\n",
    "        0: [0, 1, 2],      # Client 0 gets digits 0 and 1\n",
    "        1: [2, 3],      # Client 1 gets digits 2 and 3\n",
    "        2: [4, 5],      # Client 2 gets digits 4 and 5\n",
    "        3: [5, 6, 7],      # Client 3 gets digits 6 and 7\n",
    "        4: [8, 9, 1],\n",
    "        5: [1, 2, 3],\n",
    "        6 : [4, 5, 6],\n",
    "        7 : [7,  9],\n",
    "        8 : [0, 1],\n",
    "        9 : [3, 5]\n",
    "                    # Client 4 gets digits 8 and 9\n",
    "    }\n",
    "    \n",
    "    # Assign data to each client based on digits\n",
    "    for client_id, digits in client_digits.items():\n",
    "        for digit in digits:\n",
    "            digit_indices = np.where(labels == digit)[0]\n",
    "            dict_users[client_id] = np.concatenate((dict_users[client_id], digit_indices))\n",
    "            \n",
    "    return dict_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"Average the weights of models\"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataset, device):\n",
    "    \"\"\"\n",
    "    Test the model and return accuracy, precision, recall, and F1 score\n",
    "    Returns macro-averaged metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Initialize confusion matrix (10 classes for MNIST)\n",
    "    confusion_matrix = torch.zeros(10, 10)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Update confusion matrix\n",
    "            for t, p in zip(target.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    # Calculate metrics for each class and average\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        # True Positives: diagonal elements\n",
    "        tp = confusion_matrix[i, i]\n",
    "        # False Positives: sum of column i minus diagonal element\n",
    "        fp = confusion_matrix[:, i].sum() - tp\n",
    "        # False Negatives: sum of row i minus diagonal element\n",
    "        fn = confusion_matrix[i, :].sum() - tp\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        # Calculate recall\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate macro averages\n",
    "    macro_precision = sum(precisions) / len(precisions)\n",
    "    macro_recall = sum(recalls) / len(recalls)\n",
    "    macro_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {macro_precision:.4f}\")\n",
    "    print(f\"Recall: {macro_recall:.4f}\")\n",
    "    print(f\"F1 Score: {macro_f1:.4f}\")\n",
    "    \n",
    "    return accuracy, macro_precision, macro_recall, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_communication_costs(self, cluster_participation_history, num_rounds=10):\n",
    "    \"\"\"\n",
    "    Calculate communication costs with:\n",
    "    - 10 clients in traditional FL\n",
    "    - 3 clusters in hierarchical FL with selective participation\n",
    "    - No compression\n",
    "    \n",
    "    Args:\n",
    "        cluster_participation_history: List of lists containing participating cluster IDs for each round\n",
    "        num_rounds: Total number of training rounds\n",
    "    \"\"\"\n",
    "    # Model parameters for each layer\n",
    "    model_params = {\n",
    "        'conv1': (5*5*1*10) + 10,          # 260 parameters\n",
    "        'conv2': (5*5*10*20) + 20,         # 5,020 parameters\n",
    "        'fc1': (320*50) + 50,              # 16,050 parameters\n",
    "        'fc2': (50*10) + 10                # 510 parameters\n",
    "    }\n",
    "    \n",
    "    total_params = sum(model_params.values())  # 21,840 parameters\n",
    "    bytes_per_param = 4  # Float32\n",
    "    num_clients = 10  # Total number of clients\n",
    "    num_clusters = 3  # Number of clusters\n",
    "    \n",
    "    # Calculate base model sizes\n",
    "    model_size_bytes = total_params * bytes_per_param\n",
    "    model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    # 1. Traditional FL Communication (10 clients)\n",
    "    traditional_costs = {\n",
    "        'initial_distribution': num_clients * total_params,  # Initial model to 10 clients\n",
    "        'per_round': {\n",
    "            'client_to_server': num_clients * total_params,  # Updates from 10 clients\n",
    "            'server_to_client': num_clients * total_params   # New model to 10 clients\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    traditional_params_per_round = (\n",
    "        traditional_costs['per_round']['client_to_server'] + \n",
    "        traditional_costs['per_round']['server_to_client']\n",
    "    )\n",
    "    \n",
    "    traditional_total_params = (\n",
    "        traditional_costs['initial_distribution'] +  # Initial distribution\n",
    "        (traditional_params_per_round * num_rounds)  # Training rounds both ways\n",
    "    )\n",
    "    \n",
    "    traditional_total_mb = (traditional_total_params * bytes_per_param) / (1024 * 1024)\n",
    "    \n",
    "    # 2. Hierarchical FL Communication with Selective Participation\n",
    "    \n",
    "    # A. Initial Setup Phase (Clustering)\n",
    "    clustering_metadata = {\n",
    "        'data_distribution': 10,    # Distribution over 10 classes\n",
    "        'data_size': 1             # Number of samples\n",
    "    }\n",
    "    total_clustering_metadata = sum(clustering_metadata.values())\n",
    "    \n",
    "    initial_setup_costs = {\n",
    "        'client_metadata': num_clients * total_clustering_metadata,  # All clients send metadata\n",
    "        'cluster_assignments': num_clients,                         # Server assigns clusters\n",
    "        'head_announcements': num_clusters,                         # Server announces heads\n",
    "        'initial_model': total_params * num_clusters               # Model to cluster heads\n",
    "    }\n",
    "    \n",
    "    total_initial_setup_params = sum(initial_setup_costs.values())\n",
    "    \n",
    "    # B. Calculate actual communication per round based on participation history\n",
    "    total_round_params = 0\n",
    "    participation_stats = {\n",
    "        'rounds': [],\n",
    "        'avg_participation': 0\n",
    "    }\n",
    "    \n",
    "    for round_idx, participating_clusters in enumerate(cluster_participation_history):\n",
    "        num_participating = len(participating_clusters)\n",
    "        round_params = {\n",
    "            'head_to_server': total_params * num_participating,  # Updates from participating heads\n",
    "            'server_to_head': total_params * num_participating   # New model to participating heads\n",
    "        }\n",
    "        round_total = sum(round_params.values())\n",
    "        total_round_params += round_total\n",
    "        \n",
    "        participation_stats['rounds'].append({\n",
    "            'round': round_idx + 1,\n",
    "            'num_clusters': num_participating,\n",
    "            'params_transferred': round_total\n",
    "        })\n",
    "    \n",
    "    participation_stats['avg_participation'] = (\n",
    "        sum(len(r) for r in cluster_participation_history) / len(cluster_participation_history)\n",
    "    )\n",
    "    \n",
    "    # Total Hierarchical Communication\n",
    "    hierarchical_total_params = (\n",
    "        total_initial_setup_params +  # Setup phase\n",
    "        total_round_params           # Actual training rounds\n",
    "    )\n",
    "    \n",
    "    hierarchical_total_mb = (hierarchical_total_params * bytes_per_param) / (1024 * 1024)\n",
    "    \n",
    "    # Calculate reductions\n",
    "    param_reduction = ((traditional_total_params - hierarchical_total_params) / traditional_total_params) * 100\n",
    "    size_reduction = ((traditional_total_mb - hierarchical_total_mb) / traditional_total_mb) * 100\n",
    "    \n",
    "    # Prepare detailed results\n",
    "    results = {\n",
    "        'model_architecture': {\n",
    "            'total_parameters': total_params,\n",
    "            'size_mb': model_size_mb,\n",
    "            'parameter_breakdown': model_params\n",
    "        },\n",
    "        'traditional_fl': {\n",
    "            'num_clients': num_clients,\n",
    "            'total_params': traditional_total_params,\n",
    "            'total_mb': traditional_total_mb\n",
    "        },\n",
    "        'hierarchical_fl': {\n",
    "            'num_clusters': num_clusters,\n",
    "            'initial_setup_mb': (total_initial_setup_params * bytes_per_param) / (1024 * 1024),\n",
    "            'total_params': hierarchical_total_params,\n",
    "            'total_mb': hierarchical_total_mb,\n",
    "            'participation_stats': participation_stats\n",
    "        },\n",
    "        'reduction': {\n",
    "            'parameters_percent': param_reduction,\n",
    "            'size_percent': size_reduction\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nDetailed Communication Cost Analysis:\")\n",
    "    print(f\"\\nModel Base Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nTraditional FL (10 clients):\")\n",
    "    print(f\"Total Communication: {traditional_total_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nHierarchical FL with Selective Participation:\")\n",
    "    print(f\"Initial Setup: {results['hierarchical_fl']['initial_setup_mb']:.4f} MB\")\n",
    "    print(f\"Average Participating Clusters per Round: {participation_stats['avg_participation']:.2f}\")\n",
    "    print(f\"Total Communication: {hierarchical_total_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nReduction Achieved:\")\n",
    "    print(f\"Parameter reduction: {param_reduction:.2f}%\")\n",
    "    print(f\"Size reduction: {size_reduction:.2f}%\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset, idxs, args):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "        self.idxs = idxs\n",
    "        self.args = args\n",
    "        self.cluster_id = None\n",
    "        self.is_cluster_head = False\n",
    "        self.performance_history = []  # Track training performance\n",
    "        self.member_performance = {}  # Track member performance\n",
    "        self.last_contribution_round = 0  # Track last round of contribution\n",
    "        self.cluster_performance = []  # Track cluster's overall performance\n",
    "        self.participation_score = 1.0  # Dynamic participation score\n",
    "    \n",
    "    def should_participate(self, current_round, threshold=0.5):\n",
    "        \"\"\"Decide whether cluster should participate in current round\"\"\"\n",
    "        # Calculate participation score based on multiple factors\n",
    "        \n",
    "        # 1. Performance trend (40%)\n",
    "        performance_weight = 0.6\n",
    "        if len(self.cluster_performance) >= 2:\n",
    "            performance_trend = (self.cluster_performance[-1] - self.cluster_performance[-2])\n",
    "            # More stringent performance scoring\n",
    "            if performance_trend > 2:  # Significant improvement\n",
    "                performance_score = 1.0\n",
    "            elif performance_trend > 0:  # Modest improvement\n",
    "                performance_score = 0.7\n",
    "            else:  # No improvement or decline\n",
    "                performance_score = 0.3\n",
    "        else:\n",
    "            performance_score = 0.5  # More conservative initial score\n",
    "            \n",
    "        # 2. Rounds since last contribution (30%)\n",
    "        staleness_weight = 0.4\n",
    "        rounds_since_contribution = current_round - self.last_contribution_round\n",
    "        # Force participation after 4 rounds of non-participation\n",
    "        if rounds_since_contribution >= 4:\n",
    "            return True\n",
    "        staleness_score = min(0.8, rounds_since_contribution / 4.0)\n",
    "    \n",
    "        \n",
    "        # Calculate final participation score\n",
    "        self.participation_score = (\n",
    "            performance_weight * performance_score +\n",
    "            staleness_weight * staleness_score \n",
    "            \n",
    "        )\n",
    "        \n",
    "        # Debug print using cluster_id instead of client_id\n",
    "        print(f\"\\nParticipation Score Components for Cluster {self.cluster_id}:\")  # Changed from client_id to cluster_id\n",
    "        print(f\"Performance Score: {performance_score:.3f}\")\n",
    "        print(f\"Staleness Score: {staleness_score:.3f}\")\n",
    "        print(f\"Final Score: {self.participation_score:.3f}\")\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        \n",
    "        # Return True if score exceeds threshold\n",
    "        return self.participation_score > threshold\n",
    "    \n",
    "  \n",
    "\n",
    "    def update_cluster_performance(self, performance_metric):\n",
    "        \"\"\"Track cluster's performance\"\"\"\n",
    "        self.cluster_performance.append(performance_metric)\n",
    "        if len(self.cluster_performance) > 5:  # Keep last 5 rounds\n",
    "            self.cluster_performance.pop(0)\n",
    "        \n",
    "    def compute_data_distribution(self):\n",
    "        \"\"\"Compute distribution of data labels\"\"\"\n",
    "        labels = [self.dataset.targets[i].item() for i in self.idxs]\n",
    "        distribution = np.zeros(10)  # 10 classes for MNIST\n",
    "        for label in labels:\n",
    "            distribution[label] += 1\n",
    "        return distribution / len(labels)  # Normalize\n",
    "\n",
    "    def train_local(self, global_model):\n",
    "        \"\"\"Local training\"\"\"\n",
    "        local_model = LocalUpdate(\n",
    "            dataset=self.dataset,\n",
    "            idxs=self.idxs,\n",
    "            local_bs=self.args.local_bs,\n",
    "            local_ep=self.args.local_ep,\n",
    "            lr=self.args.lr,\n",
    "            momentum=self.args.momentum\n",
    "        )\n",
    "        weights, loss = local_model.update_weights(global_model)\n",
    "        self.performance_history.append(loss)\n",
    "        return weights, loss\n",
    "\n",
    "class ClusterHead(Client):\n",
    "    def __init__(self, client_id, dataset, idxs, args):\n",
    "        super().__init__(client_id, dataset, idxs, args)\n",
    "        self.is_cluster_head = True\n",
    "        self.cluster_members = []\n",
    "        self.member_performance = {}  # Track member performance\n",
    "        \n",
    "    def aggregate_cluster_updates(self, updates, losses):\n",
    "        \"\"\"Aggregate updates from cluster members with performance tracking\"\"\"\n",
    "        # Update member performance\n",
    "        for client_id, loss in losses.items():\n",
    "            if client_id not in self.member_performance:\n",
    "                self.member_performance[client_id] = []\n",
    "            self.member_performance[client_id].append(loss)\n",
    "            \n",
    "        return average_weights(updates)\n",
    "\n",
    "class HierarchicalServer:\n",
    "    def __init__(self, args, n_clusters=3):\n",
    "        self.args = args\n",
    "        self.n_clusters = n_clusters\n",
    "        self.clients = {}\n",
    "        self.clusters = {}\n",
    "        self.cluster_heads = {}\n",
    "        self.max_client_data = 0  # For normalization\n",
    "        self.client_history = {}  # Track client performance\n",
    "        \n",
    "    def initialize_clients(self, train_dataset, user_groups):\n",
    "        \"\"\"Initialize all clients and find max data size\"\"\"\n",
    "        for client_id in user_groups.keys():\n",
    "            self.clients[client_id] = Client(\n",
    "                client_id,\n",
    "                train_dataset,\n",
    "                user_groups[client_id],\n",
    "                self.args\n",
    "            )\n",
    "            self.max_client_data = max(\n",
    "                self.max_client_data, \n",
    "                len(user_groups[client_id])\n",
    "            )\n",
    "    \n",
    "    def calculate_distribution_score(self, client):\n",
    "        \"\"\"Calculate how well-distributed a client's data is\"\"\"\n",
    "        distribution = client.compute_data_distribution()\n",
    "        # Entropy as a measure of distribution\n",
    "        entropy = -np.sum(distribution * np.log(distribution + 1e-10))\n",
    "        # Normalize entropy\n",
    "        max_entropy = -np.log(1/10)  # Maximum entropy for 10 classes\n",
    "        return entropy / max_entropy\n",
    "    \n",
    "    def get_client_resources(self, client_id):\n",
    "        \"\"\"Placeholder for resource scoring\"\"\"\n",
    "        # Could be extended to include actual resource metrics\n",
    "        return 1.0\n",
    "        \n",
    "    def select_cluster_head(self, cluster_members):\n",
    "        \"\"\"Select cluster head based on multiple criteria\"\"\"\n",
    "        head_scores = {}\n",
    "        \n",
    "        for client_id in cluster_members:\n",
    "            client = self.clients[client_id]\n",
    "            \n",
    "            # Data quantity score (normalized)\n",
    "            data_score = len(client.idxs) / self.max_client_data\n",
    "            \n",
    "            # Distribution score\n",
    "            dist_score = self.calculate_distribution_score(client)\n",
    "            \n",
    "            \n",
    "            # Combined weighted score\n",
    "            head_scores[client_id] = (\n",
    "                0.6 * data_score +\n",
    "                0.4 * dist_score \n",
    "            )\n",
    "            \n",
    "        return max(head_scores.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    def perform_clustering(self):\n",
    "        \"\"\"Perform hierarchical clustering with improved head selection\"\"\"\n",
    "        distributions = []\n",
    "        client_ids = []\n",
    "        \n",
    "        # Collect client distributions\n",
    "        for client_id, client in self.clients.items():\n",
    "            distributions.append(client.compute_data_distribution())\n",
    "            client_ids.append(client_id)\n",
    "                \n",
    "        distributions = np.array(distributions)\n",
    "        \n",
    "        # Perform hierarchical clustering\n",
    "        linkage_matrix = linkage(distributions, method='ward')\n",
    "        cluster_labels = fcluster(linkage_matrix, \n",
    "                                t=self.n_clusters, \n",
    "                                criterion='maxclust')\n",
    "        \n",
    "        # Group clients by cluster\n",
    "        cluster_members = {}\n",
    "        for i, label in enumerate(cluster_labels):\n",
    "            cluster_id = int(label - 1)  # Convert to 0-based indexing\n",
    "            if cluster_id not in cluster_members:\n",
    "                cluster_members[cluster_id] = []\n",
    "            cluster_members[cluster_id].append(client_ids[i])\n",
    "        \n",
    "        # Select heads and assign clusters\n",
    "        for cluster_id, members in cluster_members.items():\n",
    "            # Select best head for this cluster\n",
    "            head_id = self.select_cluster_head(members)\n",
    "            \n",
    "            self.clusters[cluster_id] = members\n",
    "            self.cluster_heads[cluster_id] = ClusterHead(\n",
    "                head_id,\n",
    "                self.clients[head_id].dataset,\n",
    "                self.clients[head_id].idxs,\n",
    "                self.args\n",
    "            )\n",
    "            self.cluster_heads[cluster_id].cluster_id = cluster_id  # Set the cluster_id\n",
    "            \n",
    "            print(f\"\\nCluster {cluster_id}:\")\n",
    "            print(f\"  Head: Client {head_id}\")\n",
    "            print(f\"  Head Score Components:\")\n",
    "            client = self.clients[head_id]\n",
    "            print(f\"    - Data Score: {len(client.idxs)/self.max_client_data:.3f}\")\n",
    "            print(f\"    - Distribution Score: {self.calculate_distribution_score(client):.3f}\")\n",
    "            print(f\"  Members: {members}\")\n",
    "            \n",
    "            # Assign cluster IDs to clients\n",
    "            for member_id in members:\n",
    "                self.clients[member_id].cluster_id = cluster_id\n",
    "\n",
    "    def calculate_communication_costs(self, cluster_participation_history, num_rounds=10):\n",
    "        \"\"\"\n",
    "        Calculate communication costs with:\n",
    "        - 10 clients in traditional FL\n",
    "        - 3 clusters in hierarchical FL with selective participation\n",
    "        - No compression\n",
    "        \"\"\"\n",
    "        # Model parameters for each layer\n",
    "        model_params = {\n",
    "            'conv1': (5*5*1*10) + 10,          # 260 parameters\n",
    "            'conv2': (5*5*10*20) + 20,         # 5,020 parameters\n",
    "            'fc1': (320*50) + 50,              # 16,050 parameters\n",
    "            'fc2': (50*10) + 10                # 510 parameters\n",
    "        }\n",
    "        \n",
    "        total_params = sum(model_params.values())  # 21,840 parameters\n",
    "        bytes_per_param = 4  # Float32\n",
    "        num_clients = 10  # Total number of clients\n",
    "        num_clusters = 3  # Number of clusters\n",
    "        \n",
    "        # Calculate base model sizes\n",
    "        model_size_bytes = total_params * bytes_per_param\n",
    "        model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "        \n",
    "        # 1. Traditional FL Communication (10 clients)\n",
    "        traditional_costs = {\n",
    "            'per_round': {\n",
    "                'client_to_server': num_clients * total_params,  # Updates from 10 clients\n",
    "                'server_to_client': num_clients * total_params   # New model to 10 clients\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        traditional_params_per_round = (\n",
    "            traditional_costs['per_round']['client_to_server'] + \n",
    "            traditional_costs['per_round']['server_to_client']\n",
    "        )\n",
    "        \n",
    "        traditional_total_params = traditional_params_per_round * num_rounds\n",
    "        traditional_total_mb = (traditional_total_params * bytes_per_param) / (1024 * 1024)\n",
    "        \n",
    "        # 2. Hierarchical FL Communication with Selective Participation\n",
    "        \n",
    "        # A. Initial Setup Phase (Clustering)\n",
    "        clustering_metadata = {\n",
    "            'data_distribution': 10,    # Distribution over 10 classes\n",
    "            'data_size': 1             # Number of samples\n",
    "        }\n",
    "        total_clustering_metadata = sum(clustering_metadata.values())\n",
    "        \n",
    "        initial_setup_costs = {\n",
    "            'client_metadata': num_clients * total_clustering_metadata,  # All clients send metadata\n",
    "            'cluster_assignments': num_clients,                         # Server assigns clusters\n",
    "            'head_announcements': num_clusters                         # Server announces heads\n",
    "        }\n",
    "        \n",
    "        total_initial_setup_params = sum(initial_setup_costs.values())\n",
    "        \n",
    "        # B. Calculate actual communication based on participation history\n",
    "        total_round_params = 0\n",
    "        total_participating_clusters = 0\n",
    "        \n",
    "        for participating_clusters in cluster_participation_history:\n",
    "            num_participating = len(participating_clusters)\n",
    "            total_participating_clusters += num_participating\n",
    "            round_total = total_params * num_participating * 2  # *2 for bidirectional communication\n",
    "            total_round_params += round_total\n",
    "        \n",
    "        avg_participation = total_participating_clusters / len(cluster_participation_history)\n",
    "        \n",
    "        # Total Hierarchical Communication\n",
    "        hierarchical_total_params = total_initial_setup_params + total_round_params\n",
    "        hierarchical_total_mb = (hierarchical_total_params * bytes_per_param) / (1024 * 1024)\n",
    "        \n",
    "        # Calculate reductions\n",
    "        param_reduction = ((traditional_total_params - hierarchical_total_params) / traditional_total_params) * 100\n",
    "        size_reduction = ((traditional_total_mb - hierarchical_total_mb) / traditional_total_mb) * 100\n",
    "        \n",
    "        # Print detailed analysis\n",
    "        print(\"\\nDetailed Communication Cost Analysis:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(\"\\nModel Architecture:\")\n",
    "        print(f\"Base Model Size: {model_size_mb:.2f} MB ({total_params:,} parameters)\")\n",
    "        print(\"\\nParameter Breakdown:\")\n",
    "        for layer, params in model_params.items():\n",
    "            print(f\"- {layer}: {params:,} parameters\")\n",
    "        \n",
    "        print(\"\\nTraditional FL (10 clients):\")\n",
    "        print(f\"Per Round: {traditional_params_per_round:,} parameters ({traditional_params_per_round * bytes_per_param / (1024 * 1024):.2f} MB)\")\n",
    "        print(f\"Total Communication: {traditional_total_params:,} parameters ({traditional_total_mb:.2f} MB)\")\n",
    "        \n",
    "        print(\"\\nHierarchical FL with Selective Participation:\")\n",
    "        print(f\"Initial Clustering Setup: {total_initial_setup_params:,} parameters ({total_initial_setup_params * bytes_per_param / (1024 * 1024):.2f} MB)\")\n",
    "        print(f\"Average Participating Clusters per Round: {avg_participation:.2f}\")\n",
    "        print(f\"Total Round Communication: {total_round_params:,} parameters ({total_round_params * bytes_per_param / (1024 * 1024):.2f} MB)\")\n",
    "        print(f\"Total Communication: {hierarchical_total_params:,} parameters ({hierarchical_total_mb:.2f} MB)\")\n",
    "        \n",
    "        print(\"\\nReduction Achieved:\")\n",
    "        print(f\"Parameter reduction: {param_reduction:.2f}%\")\n",
    "        print(f\"Size reduction: {size_reduction:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'model_architecture': {\n",
    "                'total_parameters': total_params,\n",
    "                'size_mb': model_size_mb,\n",
    "                'parameter_breakdown': model_params\n",
    "            },\n",
    "            'traditional_fl': {\n",
    "                'num_clients': num_clients,\n",
    "                'total_params': traditional_total_params,\n",
    "                'total_mb': traditional_total_mb,\n",
    "                'per_round_params': traditional_params_per_round\n",
    "            },\n",
    "            'hierarchical_fl': {\n",
    "                'num_clusters': num_clusters,\n",
    "                'initial_setup_params': total_initial_setup_params,\n",
    "                'total_params': hierarchical_total_params,\n",
    "                'total_mb': hierarchical_total_mb,\n",
    "                'avg_participation': avg_participation\n",
    "            },\n",
    "            'reduction': {\n",
    "                'parameters_percent': param_reduction,\n",
    "                'size_percent': size_reduction\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def train_federated(self, train_dataset, test_dataset, user_groups):\n",
    "        \"\"\"Modified training loop with selective cluster participation\"\"\"\n",
    "        try:\n",
    "            # Initialize tracking for cluster participation\n",
    "            cluster_participation_history = []\n",
    "            global_model = CNNMnist().to(self.args.device)\n",
    "            global_model.train()\n",
    "            \n",
    "            self.initialize_clients(train_dataset, user_groups)\n",
    "            self.perform_clustering()\n",
    "            \n",
    "            # Track performance history for all clusters\n",
    "            cluster_performance_history = {cluster_id: [] for cluster_id in self.cluster_heads.keys()}\n",
    "            \n",
    "            # Use tqdm for epoch progress\n",
    "            for epoch in tqdm(range(self.args.epochs), desc=\"Training Progress\"):\n",
    "                print(f'\\nEpoch {epoch+1}/{self.args.epochs}')\n",
    "                \n",
    "                cluster_updates = {}\n",
    "                participating_clusters = []\n",
    "                \n",
    "                # Determine participating clusters\n",
    "                for cluster_id, head in self.cluster_heads.items():\n",
    "                    should_participate = head.should_participate(epoch)\n",
    "                    print(f\"\\nCluster {cluster_id} evaluation:\")\n",
    "                    print(f\"Score: {head.participation_score:.2f}\")\n",
    "                    print(f\"Threshold: {0.5}\")\n",
    "                    print(f\"Decision: {'participating' if should_participate else 'skipping'}\")\n",
    "                    \n",
    "                    if should_participate:\n",
    "                        participating_clusters.append(cluster_id)\n",
    "                \n",
    "                # Store participation history for this round\n",
    "                cluster_participation_history.append(participating_clusters.copy())\n",
    "                \n",
    "                # Modified minimum participation requirement\n",
    "                if len(participating_clusters) < max(1, len(self.cluster_heads) // 3):\n",
    "                    if epoch == 0:\n",
    "                        # For first epoch, select based on data distribution and quantity\n",
    "                        cluster_scores = {}\n",
    "                        for cluster_id, head in self.cluster_heads.items():\n",
    "                            dist_score = self.calculate_distribution_score(head)\n",
    "                            data_score = len(head.idxs) / max(len(c.idxs) for c in self.cluster_heads.values())\n",
    "                            cluster_scores[cluster_id] = 0.6 * dist_score + 0.4 * data_score\n",
    "                        \n",
    "                        best_cluster = max(cluster_scores.items(), key=lambda x: x[1])[0]\n",
    "                    else:\n",
    "                        # Use performance history for subsequent epochs\n",
    "                        avg_performances = {\n",
    "                            cid: np.mean(history) if history else 0 \n",
    "                            for cid, history in cluster_performance_history.items()\n",
    "                        }\n",
    "                        best_cluster = max(avg_performances.items(), key=lambda x: x[1])[0]\n",
    "                    \n",
    "                    if best_cluster not in participating_clusters:\n",
    "                        participating_clusters.append(best_cluster)\n",
    "                        print(f\"\\nForcing cluster {best_cluster} to participate\")\n",
    "                \n",
    "                # Train participating clusters\n",
    "                for cluster_id in participating_clusters:\n",
    "                    head = self.cluster_heads[cluster_id]\n",
    "                    cluster_members = self.clusters[cluster_id]\n",
    "                    member_updates = []\n",
    "                    member_losses = {}\n",
    "                    \n",
    "                    print(f\"\\nTraining Cluster {cluster_id}\")\n",
    "                    \n",
    "                    # Train cluster members\n",
    "                    for client_id in tqdm(cluster_members, desc=f\"Training Cluster {cluster_id} Members\"):\n",
    "                        if client_id != head.client_id:\n",
    "                            try:\n",
    "                                weights, loss = self.clients[client_id].train_local(\n",
    "                                    copy.deepcopy(global_model)\n",
    "                                )\n",
    "                                member_updates.append(weights)\n",
    "                                member_losses[client_id] = loss\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error training client {client_id}: {str(e)}\")\n",
    "                                continue\n",
    "                    \n",
    "                    # Train cluster head\n",
    "                    try:\n",
    "                        head_weights, head_loss = head.train_local(copy.deepcopy(global_model))\n",
    "                        member_updates.append(head_weights)\n",
    "                        member_losses[head.client_id] = head_loss\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error training cluster head {head.client_id}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    if member_updates:\n",
    "                        cluster_updates[cluster_id] = head.aggregate_cluster_updates(\n",
    "                            member_updates,\n",
    "                            member_losses\n",
    "                        )\n",
    "                        head.last_contribution_round = epoch\n",
    "                \n",
    "                # Global aggregation\n",
    "                if cluster_updates:\n",
    "                    try:\n",
    "                        global_weights = average_weights(list(cluster_updates.values()))\n",
    "                        global_model.load_state_dict(global_weights)\n",
    "                        \n",
    "                        # Silent evaluation for updating cluster performance\n",
    "                        accuracy, _, _, _ = test_model(\n",
    "                            model=global_model, \n",
    "                            test_dataset=test_dataset, \n",
    "                            device=self.args.device\n",
    "                        )\n",
    "                        \n",
    "                        # Update performance metrics for participating clusters\n",
    "                        for cluster_id in participating_clusters:\n",
    "                            cluster_performance_history[cluster_id].append(accuracy)\n",
    "                            self.cluster_heads[cluster_id].update_cluster_performance(accuracy)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nError in evaluation: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                print('-' * 50)\n",
    "            \n",
    "            # Calculate final communication costs\n",
    "            communication_results = self.calculate_communication_costs(\n",
    "                cluster_participation_history,\n",
    "                num_rounds=self.args.epochs\n",
    "            )\n",
    "            \n",
    "            # Final evaluation\n",
    "            final_accuracy, final_precision, final_recall, final_f1 = test_model(\n",
    "                model=global_model,\n",
    "                test_dataset=test_dataset,\n",
    "                device=self.args.device\n",
    "            )\n",
    "            \n",
    "            # Prepare final results\n",
    "            final_results = {\n",
    "                'model': global_model,\n",
    "                'final_accuracy': final_accuracy,\n",
    "                'communication_costs': communication_results,\n",
    "                'cluster_participation_history': cluster_participation_history\n",
    "            }\n",
    "            \n",
    "            return final_results\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"\\nUnexpected error: {str(e)}\")\n",
    "            raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 1:\n",
      "  Head: Client 0\n",
      "  Head Score Components:\n",
      "    - Data Score: 0.989\n",
      "    - Distribution Score: 0.476\n",
      "  Members: [0, 4, 8]\n",
      "\n",
      "Cluster 2:\n",
      "  Head: Client 5\n",
      "  Head Score Components:\n",
      "    - Data Score: 1.000\n",
      "    - Distribution Score: 0.477\n",
      "  Members: [1, 5, 9]\n",
      "\n",
      "Cluster 0:\n",
      "  Head: Client 3\n",
      "  Head Score Components:\n",
      "    - Data Score: 0.935\n",
      "    - Distribution Score: 0.476\n",
      "  Members: [2, 3, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.000\n",
      "Final Score: 0.300\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.30\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.000\n",
      "Final Score: 0.300\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.30\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.000\n",
      "Final Score: 0.300\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.30\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Forcing cluster 2 to participate\n",
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:25<00:00,  8.53s/it]\n",
      "Training Progress:  10%|█         | 1/10 [00:48<07:14, 48.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 12.84%\n",
      "Precision: 0.0441\n",
      "Recall: 0.1266\n",
      "F1 Score: 0.0493\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.400\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.40\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.400\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.40\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.400\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.40\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Forcing cluster 2 to participate\n",
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:29<00:00,  9.72s/it]\n",
      "Training Progress:  20%|██        | 2/10 [01:42<06:53, 51.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 20.29%\n",
      "Precision: 0.1499\n",
      "Recall: 0.1980\n",
      "F1 Score: 0.0898\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 3/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.500\n",
      "Final Score: 0.500\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.50\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.500\n",
      "Final Score: 0.500\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.50\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:36<00:00, 12.08s/it]\n",
      "Training Progress:  30%|███       | 3/10 [02:44<06:34, 56.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 29.88%\n",
      "Precision: 0.2335\n",
      "Recall: 0.2844\n",
      "F1 Score: 0.1796\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 4/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.750\n",
      "Final Score: 0.600\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.60\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.750\n",
      "Final Score: 0.600\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.60\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:33<00:00, 11.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 0 Members: 100%|██████████| 4/4 [00:49<00:00, 12.40s/it]\n",
      "Training Progress:  40%|████      | 4/10 [05:48<10:42, 107.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 40.06%\n",
      "Precision: 0.1847\n",
      "Recall: 0.3935\n",
      "F1 Score: 0.2431\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 5/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.400\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.40\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.400\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.40\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:45<00:00, 15.25s/it]\n",
      "Training Progress:  50%|█████     | 5/10 [07:14<08:16, 99.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 34.71%\n",
      "Precision: 0.2145\n",
      "Recall: 0.3345\n",
      "F1 Score: 0.2270\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 6/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.500\n",
      "Final Score: 0.500\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.50\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 0.300\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.280\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.28\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.500\n",
      "Final Score: 0.500\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.50\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Forcing cluster 1 to participate\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:53<00:00, 17.91s/it]\n",
      "Training Progress:  60%|██████    | 6/10 [08:40<06:19, 94.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 41.91%\n",
      "Precision: 0.4958\n",
      "Recall: 0.4050\n",
      "F1 Score: 0.3198\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 7/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 0.700\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.520\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.52\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 0.300\n",
      "Staleness Score: 0.500\n",
      "Final Score: 0.380\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.38\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 0.500\n",
      "Staleness Score: 0.750\n",
      "Final Score: 0.600\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.60\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:39<00:00, 13.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 0 Members: 100%|██████████| 4/4 [01:07<00:00, 16.86s/it]\n",
      "Training Progress:  70%|███████   | 7/10 [11:24<05:51, 117.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 64.48%\n",
      "Precision: 0.7060\n",
      "Recall: 0.6402\n",
      "F1 Score: 0.5720\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 8/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 0.300\n",
      "Staleness Score: 0.750\n",
      "Final Score: 0.480\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.48\n",
      "Threshold: 0.5\n",
      "Decision: skipping\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:41<00:00, 13.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 0 Members: 100%|██████████| 4/4 [01:07<00:00, 16.95s/it]\n",
      "Training Progress:  80%|████████  | 8/10 [14:20<04:31, 135.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 77.69%\n",
      "Precision: 0.8494\n",
      "Recall: 0.7753\n",
      "F1 Score: 0.7674\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 9/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.48\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:48<00:00, 16.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:44<00:00, 14.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 0 Members: 100%|██████████| 4/4 [01:01<00:00, 15.40s/it]\n",
      "Training Progress:  90%|█████████ | 9/10 [18:37<02:53, 173.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 83.51%\n",
      "Precision: 0.8693\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.8253\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 10/10\n",
      "\n",
      "Participation Score Components for Cluster 1:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 1 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 2:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 2 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Participation Score Components for Cluster 0:\n",
      "Performance Score: 1.000\n",
      "Staleness Score: 0.250\n",
      "Final Score: 0.700\n",
      "Threshold: 0.5\n",
      "\n",
      "Cluster 0 evaluation:\n",
      "Score: 0.70\n",
      "Threshold: 0.5\n",
      "Decision: participating\n",
      "\n",
      "Training Cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 1 Members: 100%|██████████| 3/3 [00:56<00:00, 18.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 2 Members: 100%|██████████| 3/3 [00:46<00:00, 15.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Cluster 0 Members: 100%|██████████| 4/4 [01:17<00:00, 19.28s/it]\n",
      "Training Progress: 100%|██████████| 10/10 [23:10<00:00, 139.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 85.01%\n",
      "Precision: 0.8783\n",
      "Recall: 0.8483\n",
      "F1 Score: 0.8383\n",
      "--------------------------------------------------\n",
      "\n",
      "Detailed Communication Cost Analysis:\n",
      "==================================================\n",
      "\n",
      "Model Architecture:\n",
      "Base Model Size: 0.08 MB (21,840 parameters)\n",
      "\n",
      "Parameter Breakdown:\n",
      "- conv1: 260 parameters\n",
      "- conv2: 5,020 parameters\n",
      "- fc1: 16,050 parameters\n",
      "- fc2: 510 parameters\n",
      "\n",
      "Traditional FL (10 clients):\n",
      "Per Round: 436,800 parameters (1.67 MB)\n",
      "Total Communication: 4,368,000 parameters (16.66 MB)\n",
      "\n",
      "Hierarchical FL with Selective Participation:\n",
      "Initial Clustering Setup: 123 parameters (0.00 MB)\n",
      "Average Participating Clusters per Round: 1.50\n",
      "Total Round Communication: 655,200 parameters (2.50 MB)\n",
      "Total Communication: 655,323 parameters (2.50 MB)\n",
      "\n",
      "Reduction Achieved:\n",
      "Parameter reduction: 85.00%\n",
      "Size reduction: 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 85.01%\n",
      "Precision: 0.8783\n",
      "Recall: 0.8483\n",
      "F1 Score: 0.8383\n",
      "\n",
      "Training Complete!\n",
      "Final Test Accuracy: 85.01%\n",
      "\n",
      "Communication Cost Summary:\n",
      "Traditional FL Total: 16.66 MB\n",
      "Hierarchical FL Total: 2.50 MB\n",
      "Reduction: 85.00%\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "if __name__ == '__main__':\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            # Training parameters\n",
    "            self.epochs = 10\n",
    "            self.num_users = 10\n",
    "            self.frac = 1\n",
    "            self.local_ep = 3\n",
    "            self.local_bs = 32\n",
    "            self.lr = 0.01\n",
    "            self.momentum = 0.5\n",
    "            \n",
    "            # System parameters\n",
    "            self.iid = 0  # 1 for IID, 0 for non-IID\n",
    "            # Set device after initialization\n",
    "            self.device = None\n",
    "            self.gpu = None\n",
    "            \n",
    "        def initialize_device(self):\n",
    "            \"\"\"Initialize device after torch is fully imported\"\"\"\n",
    "            self.gpu = torch.cuda.is_available()\n",
    "            self.device = 'cuda' if self.gpu else 'cpu'\n",
    "    # Initialize arguments\n",
    "    args = Args()\n",
    "    args.initialize_device()\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Generate user groups\n",
    "    user_groups = mnist_noniid(train_dataset, args.num_users)\n",
    "    \n",
    "    # Initialize and train\n",
    "    server = HierarchicalServer(args, n_clusters=3)\n",
    "    results = server.train_federated(train_dataset, test_dataset, user_groups)\n",
    "    \n",
    "    if results is not None:\n",
    "        print(\"\\nTraining Complete!\")\n",
    "        print(f\"Final Test Accuracy: {results['final_accuracy']:.2f}%\")\n",
    "        print(\"\\nCommunication Cost Summary:\")\n",
    "        print(f\"Traditional FL Total: {results['communication_costs']['traditional_fl']['total_mb']:.2f} MB\")\n",
    "        print(f\"Hierarchical FL Total: {results['communication_costs']['hierarchical_fl']['total_mb']:.2f} MB\")\n",
    "        print(f\"Reduction: {results['communication_costs']['reduction']['size_percent']:.2f}%\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
